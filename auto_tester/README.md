# Automated Test Suite

This directory contains a comprehensive automated test suite that simulates the actual automated scoring environment for the payment transaction engine.

## Purpose

- **Validate submission**: Ensures the solution passes all expected automated tests
- **Regression testing**: Quickly verify changes don't break existing functionality
- **Documentation**: Provides clear examples of expected behavior
- **Confidence**: Demonstrates the solution works correctly across all scenarios

## Structure

```
auto_tester/
â”œâ”€â”€ run_tests.sh          # Main test runner script
â”œâ”€â”€ scenarios/            # Input CSV test files (14 test cases)
â”‚   â”œâ”€â”€ 01_basic_deposits_withdrawals.csv
â”‚   â”œâ”€â”€ 02_dispute_resolve.csv
â”‚   â”œâ”€â”€ 03_dispute_chargeback.csv
â”‚   â”œâ”€â”€ 04_insufficient_funds.csv
â”‚   â”œâ”€â”€ 05_multiple_clients.csv
â”‚   â”œâ”€â”€ 06_decimal_precision.csv
â”‚   â”œâ”€â”€ 07_locked_account.csv
â”‚   â”œâ”€â”€ 08_invalid_transactions.csv
â”‚   â”œâ”€â”€ 09_whitespace.csv
â”‚   â”œâ”€â”€ 10_dispute_partial_withdrawal.csv
â”‚   â”œâ”€â”€ 11_empty.csv
â”‚   â”œâ”€â”€ 12_client_mismatch.csv
â”‚   â”œâ”€â”€ 13_multiple_disputes.csv
â”‚   â””â”€â”€ 14_large_amounts.csv
â”œâ”€â”€ expected/             # Expected output CSV files
â”‚   â””â”€â”€ <corresponding test outputs>
â””â”€â”€ README.md            # This file
```

## Running Tests

### Quick Run

```bash
./auto_tester/run_tests.sh
```

### From Project Root

```bash
cd /path/to/pay
./auto_tester/run_tests.sh
```

## Test Coverage

### Core Functionality (Tests 1-3)
- âœ… **01: Basic deposits and withdrawals** - Fundamental operations
- âœ… **02: Dispute â†’ resolve** - Dispute workflow completion
- âœ… **03: Dispute â†’ chargeback** - Dispute workflow with account locking

### Error Handling (Tests 4, 8)
- âœ… **04: Insufficient funds** - Withdrawals fail gracefully, total unchanged
- âœ… **08: Invalid transactions** - Invalid types ignored silently

### Multiple Clients (Test 5)
- âœ… **05: Multiple clients** - Concurrent account handling

### Precision & Formatting (Tests 6, 9, 14)
- âœ… **06: Decimal precision** - 1-4 decimal places accepted and output correctly
- âœ… **09: Whitespace** - CSV whitespace handling per spec
- âœ… **14: Large amounts** - High-value transactions

### Account States (Test 7)
- âœ… **07: Locked account** - All operations rejected after chargeback

### Complex Scenarios (Tests 10, 12, 13)
- âœ… **10: Dispute after withdrawal** - Partial fund disputes
- âœ… **12: Client mismatch** - Wrong client disputes ignored
- âœ… **13: Multiple disputes** - Concurrent dispute tracking

### Edge Cases (Test 11)
- âœ… **11: Empty CSV** - Handles empty input gracefully

## Test Runner Features

### Automated Comparison
- Builds the project in release mode
- Runs each scenario against the binary
- Compares actual output with expected output
- **Handles row ordering**: Normalizes CSVs before comparison (brief specifies "row ordering does not matter")

### Clear Reporting
- âœ“ Green checkmarks for passing tests
- âœ— Red X for failing tests
- Summary statistics
- Diff output for failures

### Exit Codes
- **0**: All tests passed (ready for submission)
- **1**: One or more tests failed (fix before submission)

## Expected Output Format

All expected outputs follow the brief specification:

```csv
client,available,held,total,locked
<client_id>,<amount>,<amount>,<amount>,<true|false>
```

With:
- Exactly 4 decimal places for all amounts
- Values satisfy: `total = available + held`
- `locked` is `true` after chargeback, `false` otherwise
- Row ordering is non-deterministic (test runner handles this)

## Adding New Tests

1. Create input CSV in `scenarios/`:
   ```bash
   echo "type,client,tx,amount
   deposit,1,1,100.0" > scenarios/15_my_test.csv
   ```

2. Generate expected output:
   ```bash
   cargo run --release -- scenarios/15_my_test.csv > expected/15_my_test.csv
   ```

3. Verify manually that the output is correct

4. Run test suite:
   ```bash
   ./auto_tester/run_tests.sh
   ```

## Integration with CI/CD

This test suite can be integrated into CI/CD pipelines:

```yaml
# Example GitHub Actions workflow
- name: Run automated tests
  run: ./auto_tester/run_tests.sh
```

## Comparison with Manual Testing

**Advantages over manual testing:**
- âœ… Repeatable: Run anytime, always same results
- âœ… Fast: All 14 tests run in ~1 second
- âœ… Comprehensive: Covers all brief requirements
- âœ… Regression-proof: Catches breaking changes immediately
- âœ… Documentation: Tests serve as executable specifications

## Test Philosophy

These tests are designed to:

1. **Mirror automated scoring**: Uses same I/O as actual evaluation
2. **Cover all requirements**: Every brief requirement has test coverage
3. **Validate edge cases**: Tests boundary conditions and error paths
4. **Prove correctness**: Passing all tests demonstrates compliance
5. **Build confidence**: Reduces submission anxiety

## Success Criteria

When `run_tests.sh` shows:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ALL TESTS PASSED - Ready for submission! ğŸ‰              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

You can be confident the solution will pass automated scoring.

## Troubleshooting

### Test fails but output looks correct
- Check for trailing whitespace differences
- Verify decimal precision (exactly 4 places)
- Ensure CSV header matches exactly

### Binary not found
```bash
cargo build --release
```

### Permission denied
```bash
chmod +x auto_tester/run_tests.sh
```

## Maintenance

- Tests are deterministic and should not require updates
- If brief requirements change, update corresponding test cases
- Keep expected outputs in sync with actual behavior changes
